{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 10 Posts First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tweepy\n",
    "import json\n",
    "\n",
    "# Set your Twitter API credentials\n",
    "API_KEY = 'your_api_key'\n",
    "API_SECRET = 'your_api_secret'\n",
    "BEARER_TOKEN = 'your_bearer_token'\n",
    "\n",
    "# Initialize the client\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Search parameters\n",
    "query = 'AI art ethical -is:retweet'  # Search keyword, excluding retweets\n",
    "max_results = 10  # Number of tweets per request (maximum 100)\n",
    "total_tweets_to_fetch = 10  # Total number of tweets to fetch\n",
    "\n",
    "tweets = []  # To store fetched tweets\n",
    "next_token = None  # Pagination token\n",
    "pause_time = 3 * 60  # Pause time (3 minutes)\n",
    "\n",
    "while len(tweets) < total_tweets_to_fetch:\n",
    "    try:\n",
    "        # Call the API to fetch tweets\n",
    "        response = client.search_recent_tweets(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            next_token=next_token\n",
    "        )\n",
    "\n",
    "        # If data is returned, add it to the result\n",
    "        if response.data:\n",
    "            tweets.extend(response.data)\n",
    "            print(f\"Total tweets fetched so far: {len(tweets)}\")\n",
    "        else:\n",
    "            print(\"No more tweets to fetch.\")\n",
    "            break\n",
    "\n",
    "        # Get the next page token\n",
    "        next_token = response.meta.get('next_token')\n",
    "        if not next_token:\n",
    "            print(\"All pages have been retrieved.\")\n",
    "            break\n",
    "\n",
    "    except tweepy.TooManyRequests:\n",
    "        # Handle rate limit errors (HTTP 429)\n",
    "        print(f\"Rate limit reached, pausing for {pause_time // 60} minutes...\")\n",
    "        time.sleep(pause_time)  # Pause for 3 minutes and then continue\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle other exceptions\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        break\n",
    "\n",
    "# Ensure no duplicate tweets in the result\n",
    "tweets = list({tweet.id: tweet for tweet in tweets}.values())\n",
    "\n",
    "# Convert the tweets to a dictionary list for JSON serialization\n",
    "tweet_data = [{\"id\": tweet.id, \"text\": tweet.text, \"created_at\": str(tweet.created_at)} for tweet in tweets]\n",
    "\n",
    "# Save tweets to a JSON file\n",
    "output_file = 'tweets.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(tweet_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"A total of {len(tweets)} tweets were fetched and saved to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
